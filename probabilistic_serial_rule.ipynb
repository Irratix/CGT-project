{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all possible partial preference profiles for one agent\n",
    "def generate_preferences(house_amt):\n",
    "    return list(permutations(range(house_amt)))\n",
    "\n",
    "# generate partial preference profile\n",
    "def generate_preference(house_amt):\n",
    "    return random.sample(range(house_amt), house_amt)\n",
    "\n",
    "# generate preference profile\n",
    "def generate_profile(agent_amt, house_amt):\n",
    "    profile = []\n",
    "    for agent in range(agent_amt):\n",
    "        profile.append(generate_preference(house_amt))\n",
    "    return profile\n",
    "\n",
    "# generates a hash from some profile, useful for preventing non-halting best-response learning\n",
    "def hash_profile(profile):\n",
    "    return hash(tuple(tuple(agent) for agent in profile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Serial Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probability matrix using the probabilistic serial rule\n",
    "def probability_matrix(profile):\n",
    "    agent_amt = len(profile)\n",
    "    house_amt = len(profile[0])\n",
    "    # init data of how much of each house is remaining and who ate how much\n",
    "    houses = [1] * house_amt\n",
    "    agents = [[0] * house_amt for _ in range(agent_amt)]\n",
    "\n",
    "    # probabilistic serial rule\n",
    "    while max(houses) != 0:\n",
    "        # for each player, find out which house they're eating\n",
    "        houses_selected = [next(i for i in preference if houses[i] != 0) for preference in profile]\n",
    "\n",
    "        # how long does it take to eat each house\n",
    "        house_counts = Counter(houses_selected)\n",
    "        total_rate_eaten = [house_counts.get(i, 0) for i in range(house_amt)]\n",
    "        time_to_eat = [None if total_rate_eaten[i] == 0 else houses[i] / total_rate_eaten[i] # Condition to avoid division by zero\n",
    "                 for i in range(house_amt)]\n",
    "\n",
    "        # take the lowest time to eat and step forward that amount of time\n",
    "        t = min(t for t in time_to_eat if t is not None) # poor second condition to avoid floating point errors\n",
    "        for agent in range(agent_amt):\n",
    "            house = houses_selected[agent]\n",
    "            houses[house] -= t\n",
    "            agents[agent][house] += t\n",
    "        houses = [house if house > 1e-9 else 0 for house in houses] # \n",
    "    return agents\n",
    "\n",
    "# calculate expected utility for one player from applying Borda scores of a profile to a probability matrix\n",
    "# Borda score starts at 0\n",
    "def expected_utility(matrix, profile, agent):\n",
    "    agent_amt = len(profile)\n",
    "    house_amt = len(profile[agent])\n",
    "    utility = 0\n",
    "    for house in range(house_amt):\n",
    "        house_value = house_amt - 1 - profile[agent].index(house)\n",
    "        utility += matrix[agent][house] * house_value\n",
    "    return utility\n",
    "\n",
    "# calculate expected utility for all players, see def expected_utility for detail\n",
    "def expected_utilities(matrix, profile):\n",
    "    agent_amt = len(profile)\n",
    "    return [expected_utility(matrix, profile, agent) for agent in range(agent_amt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best-Response Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a certain true profile, and a certain player, find a best response for that player and its utility\n",
    "def find_best_response(true_profile, profile, agent):\n",
    "    house_amt = len(profile[agent])\n",
    "    profile = deepcopy(profile)\n",
    "    # Prioritize the current action, if supplied\n",
    "    best_eu = -1\n",
    "    best_a = profile[agent]\n",
    "    if profile[agent] != None:\n",
    "        matrix = probability_matrix(profile)\n",
    "        best_eu = expected_utility(matrix, true_profile, agent)\n",
    "\n",
    "    # Loop over the agent's action space\n",
    "    for action in generate_preferences(house_amt):\n",
    "        profile[agent] = action\n",
    "        matrix = probability_matrix(profile)\n",
    "        eu = expected_utility(matrix, true_profile, agent)\n",
    "        if eu > best_eu:\n",
    "            best_eu = eu\n",
    "            best_a = action\n",
    "    return [list(best_a), best_eu]\n",
    "\n",
    "# Check if the current profile is a PNE\n",
    "def is_PNE(true_profile, profile):\n",
    "    agent_amt = len(profile)\n",
    "    matrix = probability_matrix(profile)\n",
    "    eu = expected_utilities(matrix, true_profile)\n",
    "    for agent in range(agent_amt):\n",
    "        _, br_eu = find_best_response(true_profile, profile, agent)\n",
    "        if br_eu > eu[agent]:\n",
    "            # reported preference is not a best response, so this is not a PNE\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Performs best-response learning\n",
    "# Returns the PNE and the amount of steps to reach it if a PNE is found\n",
    "# Returns None and the amount of steps to reach a loop and the length of the loop if a loop is found\n",
    "def best_response_learning(true_profile, profile, visited=None, depth = 0):\n",
    "    # print(\"Current profile: \", profile)\n",
    "    if visited is None:\n",
    "        visited = []\n",
    "    # Loop detected, no PNE found here\n",
    "    h = hash_profile(profile)\n",
    "    if h in visited:\n",
    "        return [None, visited.index(h), depth - visited.index(h)]\n",
    "    \n",
    "    visited.append(h)\n",
    "    agent_amt = len(profile)\n",
    "    house_amt = len(profile[0])\n",
    "    \n",
    "    matrix = probability_matrix(profile)\n",
    "    eu = expected_utilities(matrix, true_profile)\n",
    "    # print(\"Current EUs: \", eu)\n",
    "    for agent in range(agent_amt):\n",
    "        br, br_eu = find_best_response(true_profile, profile, agent)\n",
    "        if br_eu > eu[agent]:\n",
    "            # print(agent, br_eu, eu)\n",
    "            profile = deepcopy(profile)\n",
    "            profile[agent] = br\n",
    "            return best_response_learning(true_profile, profile, visited, depth + 1)\n",
    "    return [profile, depth]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce two files for each combination of amount of agents and amount of houses that we want to test.\n",
    "The first file contains only data about a true preference.\n",
    "The second file contains data for true/reported preference pairs.\n",
    "The amount of samples in second file, as well as the amount of agents and houses, is mostly limited by computational cost, as the game matrix grows exponentially with amount of agents and by the factorial of the number of houses.\n",
    "We collect the following data for arbitrarily generated profiles:\n",
    "- The content of the preference profile by agent\n",
    "- Whether the true preference profile is a PNE\n",
    "- What portion of possible reported profiles are a PNE (this is estimated by sampling as testing the entire matrix may be infeasible)\n",
    "- Whether performing deterministic best-response learning from an arbitrary position results in a PNE\n",
    "- If a PNE is reached, how many iterations it took to get there\n",
    "- If a loop is reached, how many steps it took to enter the loop\n",
    "- If a loop is reached, how many steps long the loop is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DATA COLLECTION: produce identifier data from a true profile\n",
    "def true_id_data(id, profile):\n",
    "    agent_amt = len(profile)\n",
    "    data = {}\n",
    "    data[\"ID\"] = id\n",
    "    for agent in range(agent_amt):\n",
    "        data[f\"P_{agent}\"] = \"-\".join(map(str, profile[agent]))\n",
    "    return data\n",
    "\n",
    "# FOR DATA COLLECTION: produce identifier data from a sampled profile\n",
    "def sampled_id_data(true_id, sample_id, true_profile, profile):\n",
    "    agent_amt = len(profile)\n",
    "    data = true_id_data(true_id, true_profile)\n",
    "    data[\"sample ID\"] = sample_id\n",
    "    for agent in range(agent_amt):\n",
    "        data[f\"a_{agent}\"] = \"-\".join(map(str, profile[agent]))\n",
    "    return data\n",
    "\n",
    "# FOR DATA COLLECTION: write data to file\n",
    "def write_csv(name, data):\n",
    "    folder = \"data\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(os.path.join(folder, name + \".csv\"), mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "SAMPLES = 10 # samples per category\n",
    "RANDOM_TESTS = 10 # for each sample we want to do a number of tests from arbitrary positions\n",
    "MAX_AGENTS = 5\n",
    "MAX_HOUSES = 4\n",
    "for house_amt in range(2, MAX_HOUSES + 1):\n",
    "    for agent_amt in range(2, MAX_AGENTS + 1):\n",
    "        pref_data = []\n",
    "        sampled_data = []\n",
    "        for i in range(SAMPLES):\n",
    "            true_profile = generate_profile(agent_amt, house_amt)\n",
    "            # data that applies to one true profile\n",
    "            pref_datapoint = true_id_data(i, true_profile)\n",
    "            pref_datapoint[\"is_PNE\"] = \"yes\" if is_PNE(true_profile, true_profile) else \"no\"\n",
    "            pref_datapoint[\"est. PNEs%\"] = 0 # gets filled in within the sampling loop\n",
    "\n",
    "            for j in range(RANDOM_TESTS):\n",
    "                profile = generate_profile(agent_amt, house_amt)\n",
    "                if is_PNE(true_profile, profile):\n",
    "                    pref_datapoint[\"est. PNEs%\"] += 100 / RANDOM_TESTS\n",
    "                \n",
    "                # data that applies to individual samples\n",
    "                sampled_datapoint = sampled_id_data(i, j, true_profile, profile)\n",
    "                brl = best_response_learning(true_profile, profile)\n",
    "                if brl[0] is not None:\n",
    "                    sampled_datapoint[\"PNE reached\"] = \"yes\"\n",
    "                    sampled_datapoint[\"steps to PNE\"] = brl[1]\n",
    "                    # not applicable data should still get a key\n",
    "                    sampled_datapoint[\"Steps to loop\"] = \"-\"\n",
    "                    sampled_datapoint[\"Loop length\"] = \"-\"\n",
    "                else:\n",
    "                    sampled_datapoint[\"PNE reached\"] = \"no\"\n",
    "                    sampled_datapoint[\"Steps to loop\"] = brl[1]\n",
    "                    sampled_datapoint[\"Loop length\"] = brl[2]\n",
    "                    # not applicable data should still get a key\n",
    "                    sampled_datapoint[\"steps to PNE\"] = \"-\"\n",
    "                sampled_data.append(sampled_datapoint)\n",
    "            pref_data.append(pref_datapoint)\n",
    "        write_csv(f\"dat1_agents={agent_amt}_houses={house_amt}\", pref_data)\n",
    "        write_csv(f\"dat2_agents={agent_amt}_houses={house_amt}\", sampled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_profile = generate_profile(5, 5)\n",
    "Profile = generate_profile(5, 5)\n",
    "print(best_response_learning(True_profile, Profile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
